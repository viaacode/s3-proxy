<html>
  <head>
    <link rel="stylesheet" href="/application.css" />
    <link rel="shortcut icon" href="/favicon.ico">
  </head>

  <body>
    <%= erb :menu, :layout => false %>

    <div class="content">
      <h2>S3 proxy API</h2>

      Upload a file with following request:
      <pre class="code">PUT '/:bucket/:file_key' </pre>

      Download a file with following request:
      <pre class="code">GET '/:bucket/:file_key'</pre>

      Get status of restoring file with following request:
      <pre class="code">HEAD '/:bucket/:file_key'</pre>

      Restore an archived file :
      <pre class="code">POST '/:bucket/:file_key?restore'</pre>

      Start multipart upload:
      <pre class="code">POST '/:bucket/:file_key'</pre>

      <p>
      For above requests to work the headers must included a signed 256 bit S3 signature in Authorization header and some others like the Host are required:
      <pre class="code">
'Authorization': 'S3 token generated by aws-sdk-s3 client',         # token signs request path, host, and some x-amz headers
'Host': 'http://s3.viaa.be:8001',                                 # host must match endpoint given in s3 client
'x-amz-date': request.env['HTTP_X_AMZ_DATE'],                       # generated by client
'x-amz-content-sha256': request.env['HTTP_X_AMZ_CONTENT_SHA256'],   # generated by client
      </pre>
      </p>
      <p>
      Details about the signature calculation <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">amazon signature</a>
      </p>


      <h2>Amazon aws-sdk-s3 client examples</h2>
      <p>
      When using Amazon's <a href="https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3.html">aws-sdk-s3</a> client libraries, available for many programming languages, the signature headers for the api calls are generated for you.
      </p>


      <h4>Requesting an S3 token</h4>
      <p>
      You provide your SAML user and password together with a secret_key in a post request to
      address
      <!--  http://s3poc.do.viaa.be:91/.TOKEN/ -->
      http://s3poc.do.viaa.be:88/_admin/manage/tenants/or-yourbucket/tokens
      As response you get a json response with token to use with the Caringo S3 server.
      <pre class="code">
require 'json'
require 'rest-client'

secret_key = "abc1234"
password = '<your password here>'

response = RestClient::Request.execute(
  method: :post,
  url: 'http://s3.viaa.be:88/_admin/manage/tenants/or-yourbucket/tokens',
  timeout: 10,
  user: 'username+or-yourbucket',
  password: password,
  headers: {
    'Content-Type': 'application/json',
    'X-User-Secret-Key-Meta': secret_key
  }
)
response = JSON.parse(response.body)
token = response['token']
      </pre>


      <h4>AWS SDK S3 client initialise with secret_key and token:</h4>
      <p>
      After receiving the token with above call use the token and your secret_key to configure your
      s3_client:
      </p>
      <p>
      <pre class="code">
require 'aws-sdk-s3'  # in Gemfile use gem 'aws-sdk-s3' and then bundle install to have latest version
Aws.config.update(
  endpoint: 'https://s3.viaa.be',
  access_key_id: token,             # retreived from previous call or supplied by us
  secret_access_key: secret_key,    # retreived from previous call or supplied by us
  region: 'belgium-vrt'
)

s3_client = Aws::S3::Client.new
      </pre>
      </p>



      <p>
      <h4>S3 PUT example:</h4>
      Limited to max 5Mb. For larger files use the multipart S3 protocol.
      <pre class="code">
file_data = open('../reportage_video.mp4').read

s3_client.put_object(
  key: 'reportage_video.mp4',
  body: file_data,
  bucket: 'or-yourbucket',  #bucket for vrt tenant
)
      </pre>
      </p>

      <p>
      <h4>S3 POST for multipart upload example:</h4>
<pre class="code">
# start multipart upload
resp = s3_client.create_multipart_upload(
  bucket: 'or-yourbucket',               # vrt tenant bucket
  key: 'multipart_upload_test.mp4'    # s3 key you want it (slashes are allowed)
)
upload_id = resp.to_h[:upload_id]

part_number = 1
file_parts = []


# upload parts in 1mb chunks
File.open local_file, 'rb' do |largefile|
  until largefile.eof?
    file_part_data = largefile.read(1024 * 1024) # read chunk

    upload_part_done = false
    until upload_part_done
      begin
        resp = s3_client.upload_part(
          body: file_part_data,
          bucket: 'or-yourbucket',
          key: 'multipart_upload_test.mp4',
          part_number: part_number,
          upload_id: upload_id
        )
        upload_part_done = true
      rescue Aws::S3::Errors::Http502Error
        print "\nS3 502 error when while uploading part #{part_number}, retrying..."
      rescue Seahorse::Client::NetworkingError
        print "\nConnection error when while uploading part #{part_number}, retrying..."
      end
    end

    # fill in etags and part numbers for finalize call later
    file_parts << {
      etag: resp.to_h[:etag],
      part_number: part_number
    }

    part_number += 1
  end
end

# finalize upload
resp = s3_client.complete_multipart_upload(
  bucket: 'your-bucket',
  key: 'multipart_upload_test.mp4',
  multipart_upload: {
    parts: file_parts
  },
  upload_id: upload_id
)

</pre>
      </p>



      <p>
      <h4>S3 GET example:</h4>
      <pre class="code">
begin
  s3_client.get_object(
    bucket: 'or-yourbucket',
    key: 'reportage_video.mp4',
    response_target: 'download_video.mp4'
  )

rescue Aws::S3::Errors::NotFound
  # this 404 error means the file has not been uploaded yet in the past
rescue Aws::S3::Errors::Forbidden
  # this happens for an archived file and you get the message
  # &lt;Message&gt; the operation is not valid for the object's storage class&lt;/Message&gt;
  # a restore request is needed and when status returns restored we can retry this download request.
rescue Aws::S3::Errors::ServiceError
  # any other error like service down or bad credentials
end
      </pre>
      </p>


      <p>
      <h4>S3 STATUS example: </h4>
      <pre class="code">
# this will return a restoring in progress or restored response
# and is also useful to get a file size without downloading the entire content
response = s3_client.head_object(
  bucket: 'or-yourbucket',
  key: 'multipart_upload_test.mp4'
)

puts "file size = #{response[:content_length]}"
puts "restore status = #{response[:restore]}"

begin
  # this call gives 404 error
  response = s3_client.head_object(
    bucket: 'or-yourbucket',  #bucket for vrt tenant
    key: 'somefile'
  )

rescue Aws::S3::Errors::NotFound
  puts 'OK: 404 for an unexisting file'
rescue Aws::S3::Errors::ServiceError
  puts 'Service error caught'
end

</pre>
S3 STATUS example output:
<pre class="code">
file size = 8239092
restore status = ongoing-request="false", expiry-date="Fri, Dec 2020 00:00:00 GMT"
OK: 404 for an unexisting file
</pre>
      </p>



      <p>
      <h4>S3 RESTORE example:</h4>
      <pre class="code">
resp = s3_client.restore_object(
  bucket: 'or-yourbucket',  #bucket for vrt tenant
  key: 'reportage_video.mp4',
  restore_request: {
    days: 1,
    glacier_job_parameters: {
      tier: 'Expedited'
    }
  }
)
      </pre>
      </p>


    </div>




  </body>
</html>
